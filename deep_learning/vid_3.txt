As a first step with keras and tensorflow, we’ll use a pre-trained deep learning model to classify what’s in a photo. 


We’ll walk through the steps in this video. Then you can then see the code and output in the kernel below.  Finally, there are instructions to fork a kernel to create the workspace for your own code.


I highly recommend you watch through this video first, before jumping down to look at the code below. It’s hard to learn if you are flipping back and forth, and you won’t get this while trying to multitask.  The code below will still be there when you finish.


Pre-trained models are saved on Kaggle. You can attach them to your kernel workspace the same way you would attach a dataset. We’ve done that in this example kernel and in your workspace.


I’ve also attached a dataset with dog pictures, and we will try to tell each dog’s breed from its picture. That data is in this directory.[q] I picked a few image files to test our model with, and I put the file paths in a list.[r]  Then I use the join function from Python’s OS.path to append the filename to the directory.  The end result is a list of paths to image files. To keep things simple, we’ll make predictions with just those few images.[s]


We need to do a little bit of processing to go from the image file paths to something we can run through our model. We’ll put all those preprocessing steps into a single function called read_and_prep_images.


Some of these preprocessing functions from keras and tensorflow will be new to you, but the workflow should start to feel more familiar once we get to how models are used.[t]




There are a few ways to store this data. Later on, we’ll learn about TensorFlow’s powerful DataSets api. For now, we’ll store the data in numpy arrays.  It’s easy to switch between the two, so we won’t make much of the distinction right now.


We load the images using the load_image function. We have a few images, so we keep them in a list for now, using a list comprehension. The target_size argument specifies the size or pixel resolution to we want the images to be when we model them. The model we’ll use was trained with 224 by 224 resolution images. So, we’ll make them have the same resolution here.


Then we convert each image into an array using the img_to_array function.


Remember from the previous video that we can store images in 3-dimensional tensors. The img_to_array function creates that 3D tensor for each image.  Combining multiple images causes us to stack those in a new dimension, so we end up with a four dimensional tensor or array.


Finally, we use a function called preprocess_input. This function does some arithmetic on the pixel values, specifically dividing the values in the input, so they are all between -1 and 1.  This was done when the model was first built, so we have to do it again here to be consistent.


This had some function calls you haven’t seen before. These calls will start feeling more familiar as you do the exercises and get used to using the commands you need.[u]


The next few lines are easier.  We specify the model much as we would in scikit-learn or other modeling frameworks.  We’ll use a type of model called the ResNet50 model. I give it an argument specifying the filepath to where we have stored the values in the convolutional filters.[v]


We’ll call that function we wrote to read and preprocess our data.


Then we get predictions by calling the predict method of our model.  This line works the same way prediction works in libraries like scikit-learn.


Ok. We have predictions about what’s in each image.  We had 4 photographs, and our model gave 1000 probabilities for each photo. What’s the chance that the image has a tiger shark? What’s the chance that it has a pomeranian? What’s the chance that it has an toothbrush? And so on.


It’s convenient to focus on the probabilities for what the model thinks is in the image, rather than all the things it says aren’t in the image. Keras includes a function called decode_predictions to extract the highest probabilities for each image. We call that function with predictions results, and tell it give us the top 3 probabilities for each photo.[w]


You’ll want to see the images too, to see if the model is making sense. So the notebook below includes code to display images.


If you know much about dog breeds, you’ll recognize that these are pretty good.


Ok.  You’ve seen the code to use this type of model.  We have an exercise for you to do it yourself.


This may still feel like magic right now, but it will come together as you play with a couple examples and then as we dive into some of the details. So, it’s your turn to use these powerful models.  Then you’ll be ready for transfer learning, so you can quickly apply these models to new applications.
